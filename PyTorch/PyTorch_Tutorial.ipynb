{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEbWLAfYz4XxxFnoNAN+uk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sourish168/Python/blob/main/PyTorch/PyTorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction and Installation\n",
        "- From https://pytorch.org/ we can download the required package of PyTorch in our machine(Linux/Mac/Windows).\n",
        "- If gpu is available then the cuda version is preferable for NVIDIA GPUs only.\n",
        "- In local mechine we have to create a virtual environment and install the appropiate version of python.\n",
        "- In Google Colab we have to install PyTorch by \"!pip install torch\" command.\n",
        "- By \"torch.cuda.is_available()\" we can check if the cuda is there or not.\n",
        "- We can use PyTorch documentation for our specific purpose. Link: https://pytorch.org/docs/stable/index.html"
      ],
      "metadata": {
        "id": "ugEeAVTRoSyj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5AKWDZRYma0V",
        "outputId": "96b7fa88-eb57-45b0-a284-588057fe61ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available() # False means there is no cuda in the machine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_9FDd0q7yip",
        "outputId": "f43772ee-b4a5-4405-83cf-7232bd313c42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Basics\n",
        "- In NumPy we have used vectors, matrices, tensors. In PyTorch everything starts with tensors i.e. 1D, 2D, nD arrays."
      ],
      "metadata": {
        "id": "p0bRM3vE8Nek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.empty(1) # Scalar\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qKcD9KK8Nyq",
        "outputId": "d6da6b15-f463-4f84-86b2-b7107de8efc2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.8665e+32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2, 3, 4) # 3D array\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD1jYWu989KS",
        "outputId": "5a3316f5-39c4-4e06-9a5a-d5f64f2b0004"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 5.7344e-30,  4.4355e-41,  5.7344e-30,  4.4355e-41],\n",
            "         [        nan,  0.0000e+00,  1.8728e+31,  1.4153e-43],\n",
            "         [ 3.2892e+14,  4.4354e-41,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "        [[ 8.9683e-44,  0.0000e+00,  2.6905e-43,  0.0000e+00],\n",
            "         [-6.3723e+09,  4.4354e-41,  0.0000e+00,  1.4013e-45],\n",
            "         [ 9.2327e-26,  3.2695e-41,  0.0000e+00,  0.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 2, 3) # 3D array of zeros\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjUbfKlg9Owk",
        "outputId": "9661b74f-b804-4bb3-feba-e7a2b80835c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2, 3, dtype = torch.float16) # 2D array of ones\n",
        "print(x)\n",
        "print(\"\\n\", x.dtype) # Prints the datatype of x\n",
        "print(\"\\n\", x.size()) # Prints the size of x\n",
        "print(\"\\n\", x.shape) # Prints the shape of x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmXwva4a9bEe",
        "outputId": "72b7ea68-5868-4a07-8f14-7ff8522f2fd9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float16)\n",
            "\n",
            " torch.float16\n",
            "\n",
            " torch.Size([2, 3])\n",
            "\n",
            " torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.5, 0.1, 3.6]) # Creates a tensor from a list\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBavwzZN-NoM",
        "outputId": "d19fb6e7-a41b-4320-dc23-25cbad068dc9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.5000, 0.1000, 3.6000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 2) # 2D array of random values\n",
        "y = torch.rand(2, 2)\n",
        "print(\"x =\\n\", x)\n",
        "print(\"\\ny =\\n\", y)\n",
        "print(\"\\nx+y =\\n\", x+y) # Addition\n",
        "print(\"\\ntorch.add(x, y) =\\n\", torch.add(x, y)) # Addition\n",
        "print(\"\\nx-y =\\n\", x-y) # Subtraction\n",
        "print(\"\\ntorch.sub(x, y) =\\n\", torch.sub(x, y)) # Subtraction\n",
        "print(\"\\nx*y =\\n\", x*y) # Multiplication\n",
        "print(\"\\ntorch.mul(x, y) =\\n\", torch.mul(x, y)) # Multiplication\n",
        "print(\"\\nx/y =\\n\", x/y) # Division\n",
        "print(\"\\ntorch.div(x, y) =\\n\", torch.div(x, y)) # Division"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rmI5Npm-xzy",
        "outputId": "8f49f8ef-d1e5-49c1-c006-8cb3b1dbb056"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =\n",
            " tensor([[0.7870, 0.4952],\n",
            "        [0.1715, 0.4954]])\n",
            "\n",
            "y =\n",
            " tensor([[0.5973, 0.2423],\n",
            "        [0.5274, 0.0733]])\n",
            "\n",
            "x+y =\n",
            " tensor([[1.3843, 0.7376],\n",
            "        [0.6989, 0.5687]])\n",
            "\n",
            "torch.add(x, y) =\n",
            " tensor([[1.3843, 0.7376],\n",
            "        [0.6989, 0.5687]])\n",
            "\n",
            "x-y =\n",
            " tensor([[ 0.1896,  0.2529],\n",
            "        [-0.3559,  0.4221]])\n",
            "\n",
            "torch.sub(x, y) =\n",
            " tensor([[ 0.1896,  0.2529],\n",
            "        [-0.3559,  0.4221]])\n",
            "\n",
            "x*y =\n",
            " tensor([[0.4701, 0.1200],\n",
            "        [0.0904, 0.0363]])\n",
            "\n",
            "torch.mul(x, y) =\n",
            " tensor([[0.4701, 0.1200],\n",
            "        [0.0904, 0.0363]])\n",
            "\n",
            "x/y =\n",
            " tensor([[1.3175, 2.0436],\n",
            "        [0.3251, 6.7598]])\n",
            "\n",
            "torch.div(x, y) =\n",
            " tensor([[1.3175, 2.0436],\n",
            "        [0.3251, 6.7598]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 2)\n",
        "y = torch.rand(2, 2)\n",
        "print(\"x =\\n\", x)\n",
        "print(\"\\ny =\\n\", y)\n",
        "print(\"\\nx+y =\\n\", x+y) # Addition\n",
        "y.add_(x) # Inplace addition\n",
        "print(\"\\nNow, y =\\n\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuDBvpal_Ji4",
        "outputId": "5e6c71dd-97fb-4d20-b0e9-9ce027e29e07"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =\n",
            " tensor([[0.6547, 0.3169],\n",
            "        [0.1159, 0.8991]])\n",
            "\n",
            "y =\n",
            " tensor([[0.6328, 0.8502],\n",
            "        [0.6011, 0.8069]])\n",
            "\n",
            "x+y =\n",
            " tensor([[1.2875, 1.1671],\n",
            "        [0.7170, 1.7060]])\n",
            "\n",
            "Now, y =\n",
            " tensor([[1.2875, 1.1671],\n",
            "        [0.7170, 1.7060]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing of a tensor in PyTorch\n",
        "x = torch.rand(5, 4)\n",
        "print(x)\n",
        "print(\"\\n\", x[:, 0]) # Prints the first column\n",
        "print(\"\\n\", x[1, :]) # Prints the second row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zml4ct74BSTi",
        "outputId": "874da762-ebe1-4740-ef9f-48dd6bca1fca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2758, 0.0263, 0.4842, 0.3037],\n",
            "        [0.9383, 0.4854, 0.5855, 0.4944],\n",
            "        [0.5045, 0.8050, 0.6152, 0.1146],\n",
            "        [0.6972, 0.2365, 0.1701, 0.5679],\n",
            "        [0.1362, 0.5831, 0.3701, 0.5951]])\n",
            "\n",
            " tensor([0.2758, 0.9383, 0.5045, 0.6972, 0.1362])\n",
            "\n",
            " tensor([0.9383, 0.4854, 0.5855, 0.4944])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping of a tensor in PyTorch\n",
        "x = torch.rand(4, 4)\n",
        "print(\"x =\", x)\n",
        "y = x.view(2, 8) # Reshapes the tensor to 2D of shape (2, 8)\n",
        "print(\"\\ny =\", y)\n",
        "z = x.view(16) # Reshapes the tensor to 1D of shape (16)\n",
        "print(\"\\nz =\", z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcKp7sX0B3Hh",
        "outputId": "8edd6946-3fb5-49dc-9c5c-b99e9d430379"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([[0.9847, 0.5975, 0.7559, 0.1402],\n",
            "        [0.5898, 0.6594, 0.3962, 0.7136],\n",
            "        [0.9404, 0.0475, 0.6655, 0.4802],\n",
            "        [0.1402, 0.3459, 0.9550, 0.7598]])\n",
            "\n",
            "y = tensor([[0.9847, 0.5975, 0.7559, 0.1402, 0.5898, 0.6594, 0.3962, 0.7136],\n",
            "        [0.9404, 0.0475, 0.6655, 0.4802, 0.1402, 0.3459, 0.9550, 0.7598]])\n",
            "\n",
            "z = tensor([0.9847, 0.5975, 0.7559, 0.1402, 0.5898, 0.6594, 0.3962, 0.7136, 0.9404,\n",
            "        0.0475, 0.6655, 0.4802, 0.1402, 0.3459, 0.9550, 0.7598])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4, 4)\n",
        "print(\"x =\", x)\n",
        "y = x.view(-1, 8) # Reshapes the tensor to 2D of shape (2, 8), Negative value by default choose the proper dimension\n",
        "print(\"\\ny =\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEamdPLhCNH_",
        "outputId": "913f3073-29f3-452c-f065-fc7112e62736"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([[0.0124, 0.9629, 0.6070, 0.7891],\n",
            "        [0.5116, 0.8248, 0.1646, 0.9194],\n",
            "        [0.5410, 0.4994, 0.0865, 0.5310],\n",
            "        [0.9660, 0.4909, 0.0985, 0.1097]])\n",
            "\n",
            "y = tensor([[0.0124, 0.9629, 0.6070, 0.7891, 0.5116, 0.8248, 0.1646, 0.9194],\n",
            "        [0.5410, 0.4994, 0.0865, 0.5310, 0.9660, 0.4909, 0.0985, 0.1097]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If there is no GPU memory then PyTorch and NumPy shares the same memory location thus the output changes\n",
        "import numpy as np\n",
        "a = torch.ones(5)\n",
        "print(\"a =\", a)\n",
        "b = a.numpy() # Creates a numpy array from a tensor\n",
        "print(\"\\nb =\", b)\n",
        "print(\"\\nType of a =\", type(a))\n",
        "print(\"\\nType of b =\", type(b))\n",
        "a.add_(1)\n",
        "print(\"\\nNow, a =\", a)\n",
        "print(\"\\nNow, b =\", b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gffkflHDDffz",
        "outputId": "ac6533c6-a794-45a0-daa0-3754bc4e7179"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a = tensor([1., 1., 1., 1., 1.])\n",
            "\n",
            "b = [1. 1. 1. 1. 1.]\n",
            "\n",
            "Type of a = <class 'torch.Tensor'>\n",
            "\n",
            "Type of b = <class 'numpy.ndarray'>\n",
            "\n",
            "Now, a = tensor([2., 2., 2., 2., 2.])\n",
            "\n",
            "Now, b = [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "print(\"a =\", a)\n",
        "b = torch.from_numpy(a) # Creates a tensor from a numpy array\n",
        "print(\"\\nb =\", b)\n",
        "print(\"\\nType of a =\", type(a))\n",
        "print(\"\\nType of b =\", type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2yMaMkrECWk",
        "outputId": "429b3e81-f0a3-4727-b4fe-79b35f971afa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a = [1. 1. 1. 1. 1.]\n",
            "\n",
            "b = tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "\n",
            "Type of a = <class 'numpy.ndarray'>\n",
            "\n",
            "Type of b = <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since in this case, torch.cuda.is_available() = False\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\") # Creates a device object\n",
        "  print(device)\n",
        "  x = torch.ones(5, device = device) # Creates a tensor on the GPU\n",
        "  y = torch.ones(5)\n",
        "  y = y.to(device) # Moves the tensor to the GPU\n",
        "  z = x + y\n",
        "  print(z)\n",
        "  z = z.to(\"cpu\") # Moves the tensor to the CPU\n",
        "  print(z)\n",
        "else:\n",
        "  print(\"No GPU available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvjH0MZdFHq9",
        "outputId": "9083337c-5773-403e-8d05-2fee31b490cd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(x) # Later for optimization steps the tensor needs to calculate the gradient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbolIfuXFnya",
        "outputId": "722b1802-f802-4958-a6ae-4d70df2857b2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Calculation with Autograd in PyTorch\n",
        "- In Deep Learning, gradient calculation is a very crutial step for optimization."
      ],
      "metadata": {
        "id": "9uY4IGU6GaOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.randn(3, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(\"x =\", x)\n",
        "y = x + 2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\ny =\", y)\n",
        "z = y*y*2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\nz =\", z)\n",
        "p = z.mean() # Creates a tensor with requires_grad = False\n",
        "print(\"\\np =\", p)\n",
        "p.backward() # Calculates the gradient of p with respect to x i.e. dp/dx\n",
        "print(\"\\nx.grad =\", x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsDXjwJzGFFG",
        "outputId": "cd836947-7965-48a7-af4a-ffebf7522a19"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([0.5580, 0.4624, 0.7128], requires_grad=True)\n",
            "\n",
            "y = tensor([2.5580, 2.4624, 2.7128], grad_fn=<AddBackward0>)\n",
            "\n",
            "z = tensor([13.0869, 12.1266, 14.7182], grad_fn=<MulBackward0>)\n",
            "\n",
            "p = tensor(13.3106, grad_fn=<MeanBackward0>)\n",
            "\n",
            "x.grad = tensor([3.4107, 3.2832, 3.6170])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad = False) # Creates a tensor with requires_grad = True\n",
        "print(\"x =\", x)\n",
        "y = x + 2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\ny =\", y)\n",
        "z = y*y*2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\nz =\", z)\n",
        "p = z.mean() # Creates a tensor with requires_grad = False\n",
        "print(\"\\np =\", p)\n",
        "p.backward() # Calculates the gradient of p with respect to x i.e. dp/dx\n",
        "print(\"\\nx.grad =\", x.grad) # Since requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "wREQhwl0ICWU",
        "outputId": "4233acd3-bba1-4f9f-c1e8-fba35a23b672"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([-1.5262,  0.2790,  1.0887])\n",
            "\n",
            "y = tensor([0.4738, 2.2790, 3.0887])\n",
            "\n",
            "z = tensor([ 0.4490, 10.3881, 19.0807])\n",
            "\n",
            "p = tensor(9.9726)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-ff0155360e09>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Creates a tensor with requires_grad = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\np =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculates the gradient of p with respect to x i.e. dp/dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nx.grad =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Since requires_grad = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(\"x =\", x)\n",
        "y = x + 2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\ny =\", y)\n",
        "z = y*y*2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\nz =\", z)\n",
        "v = torch.tensor([0.1, 10.0, 0.001], dtype = torch.float32)\n",
        "z.backward(v) # Calculates the gradient of p with respect to x i.e. dp/dx\n",
        "print(\"\\nx.grad =\", x.grad) # Vector Jacobian Product in the background"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5tsCCNuJBaH",
        "outputId": "e0c68661-553e-4def-fbd9-c69aaaea0b32"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([-0.0687, -0.8293, -0.0447], requires_grad=True)\n",
            "\n",
            "y = tensor([1.9313, 1.1707, 1.9553], grad_fn=<AddBackward0>)\n",
            "\n",
            "z = tensor([7.4598, 2.7409, 7.6466], grad_fn=<MulBackward0>)\n",
            "\n",
            "x.grad = tensor([7.7252e-01, 4.6826e+01, 7.8213e-03])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preventing gradient history\n",
        "x = torch.randn(3, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(\"x =\", x)\n",
        "x.requires_grad_(False) # Prevents gradient history\n",
        "print(\"\\nx =\", x)\n",
        "print(\"\\n\", 50*\"-\")\n",
        "x = torch.randn(3, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(\"\\nx =\", x)\n",
        "y = x.detach() # Detaches the gradient history\n",
        "print(\"\\ny =\", y)\n",
        "print(\"\\n\", 50*\"-\")\n",
        "x = torch.randn(3, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(\"\\nx =\", x)\n",
        "with torch.no_grad(): # Prevents gradient history\n",
        "  y = x + 2\n",
        "  print(\"\\ny =\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_GgOULiKfs-",
        "outputId": "dd16a121-5935-49fa-e6a2-58badd48f764"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([ 0.1956, -0.0141, -0.1218], requires_grad=True)\n",
            "\n",
            "x = tensor([ 0.1956, -0.0141, -0.1218])\n",
            "\n",
            " --------------------------------------------------\n",
            "\n",
            "x = tensor([0.6713, 0.0724, 0.5710], requires_grad=True)\n",
            "\n",
            "y = tensor([0.6713, 0.0724, 0.5710])\n",
            "\n",
            " --------------------------------------------------\n",
            "\n",
            "x = tensor([ 0.7072, -0.6595, -0.1999], requires_grad=True)\n",
            "\n",
            "y = tensor([2.7072, 1.3405, 1.8001])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy Trainning Example\n",
        "weight = torch.ones(4, requires_grad = True)\n",
        "print(\"x =\", weight, \"\\n\")\n",
        "for epoch in range(3):\n",
        "  model_output = (weight*3).sum() # Dummy model output\n",
        "  print(model_output)\n",
        "  model_output.backward()\n",
        "  print(weight.grad)\n",
        "  weight.grad.zero_() # Resets the gradient to zero, optimization step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8PbZL25Mx98",
        "outputId": "8d84185d-5fd7-4bfa-c118-126e572ddffb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([1., 1., 1., 1.], requires_grad=True) \n",
            "\n",
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization Steps\n",
        "weight = torch.ones(4, requires_grad=True)\n",
        "print(\"x =\", weight)\n",
        "optimizer = torch.optim.SGD([weight], lr=0.01)  # Pass [weight] as a single-element list, Stochastic Gradient Descent\n",
        "optimizer.step()  # Optimization step\n",
        "optimizer.zero_grad()  # Resets the gradient to zero, optimization step\n",
        "print(\"\\nOptimizer =\", optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tikk5tjzNUF3",
        "outputId": "53e8f618-692e-4469-af2b-063060a1a8b5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "\n",
            "Optimizer = SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation in PyTorch\n",
        "- To update the weights in the input of neurons of our neural network, backpropagation is needed.\n",
        "- The update rule is: wˡᵢⱼ <- (wˡᵢⱼ - η*δϵₖ/δwˡᵢⱼ), i.e. wˡᵢⱼ -= η(δϵₖ/δwˡᵢⱼ)\n",
        "- Here,\n",
        "1. wˡᵢⱼ is the weight of the input at lth layer from ith node of the (l-1)th layer to jth node of lth layer.\n",
        "2. ϵₖ = ( ̂yₖ - yₖ) be the difference between predicted output ̂yₖ and actual output yₖ of kth datapoint. Sometimes, ϵₖ is called the error function or loss function and denoted as f( ̂yₖ, yₖ), a function to find the error between actual and predicted output.\n",
        "3. η be the learning rate in which the convergence will occur. Generally we take 0 < η < 1.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fibbBN5yPrBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz # To visualize the computational graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaMTVTZQlYZd",
        "outputId": "8782e3bc-2ac1-425c-d595-8a3dff1d97cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.3.1+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torchviz)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torchviz)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torchviz)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torchviz)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torchviz)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torchviz)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->torchviz)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4132 sha256=ae1a7afe45e00c6407721b373f7d4f20e437c3ae24ea7ce1f369a9d1093d398e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchviz import make_dot # To visualize the computational graph\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad = True)\n",
        "# Forward pass and compute the loss\n",
        "y_hat = w*x\n",
        "loss = (y_hat - y)**2 # ϵₖ = f( ̂yₖ, yₖ) = ( ̂yₖ - yₖ)ᵅ, α = 2\n",
        "print(\"loss =\", loss)\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "print(\"\\nw.grad =\", w.grad)\n",
        "\n",
        "# Update weights\n",
        "# Next forward and backward pass\n",
        "# Update weights\n",
        "# Next forward and backward pass\n",
        "# And so on...\n",
        "\n",
        "\n",
        "# Visualize the computational graph\n",
        "dot = make_dot(loss, params={\"w\": w})\n",
        "dot.format = 'png'  # Set the format to PNG (you can choose other formats as well)\n",
        "dot.render(\"computational_graph\")  # Save the graph as 'computational_graph.png'\n",
        "\n",
        "# Display the graph in the notebook\n",
        "from IPython.display import Image\n",
        "Image(filename=\"computational_graph.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "7t--R8-nhfqR",
        "outputId": "f80d3e07-2caa-47e9-a850-d00018eec666"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = tensor(1., grad_fn=<PowBackward0>)\n",
            "\n",
            "w.grad = tensor(-2.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent with Autograd and Backpropagation\n"
      ],
      "metadata": {
        "id": "SoyLA9sAkTu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First, we will do this by\n",
        "1. <B>Prediction:</B> Manually\n",
        "2. <B>Gradient Calculation:</B> Manually\n",
        "3. <B>Loss Computation:</B> Manually\n",
        "4. <B>Parameters Update:</B> Manually\n"
      ],
      "metadata": {
        "id": "h6-wxVQfdBqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import torch\n",
        "import numpy as np\n",
        "# Manually finding the f = w*x using Deep Learning\n",
        "\n",
        "# Here, f = 2*x  i.e. w = 2\n",
        "X = np.array([1, 2, 3, 4], dtype = np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype = np.float32)\n",
        "w = 0.0 # Initializing the value of w = 0.0\n",
        "\n",
        "# Model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "# Loss = MSE\n",
        "def loss(y, y_predicted): # Finds the loss value\n",
        "  return ((y_predicted - y)**2).mean() # Mean Squared Error\n",
        "\n",
        "# Gradient\n",
        "# MSE = ((w*x - y)**2)/N  i.e.  δϵ/δw = 2(w*x - y)x/N\n",
        "def gradient(x, y, y_predicted): # Compute the gradient\n",
        "  return np.dot(2*x, y_predicted - y).mean()\n",
        "\n",
        "print(f\"Prediction before training: f(7) = {forward(7):.4f}\")\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.009 # Fixing the Learning Rate(η)\n",
        "n_iters = 15 # Number of iterations, change these 2 and check the outputs\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # Prediction = forward pass\n",
        "  y_predicted = forward(X)\n",
        "\n",
        "  # Loss\n",
        "  l = loss(Y, y_predicted)\n",
        "\n",
        "  # Gradients\n",
        "  dw = gradient(X, Y, y_predicted)\n",
        "\n",
        "  # Update Weights\n",
        "  w -= learning_rate*dw\n",
        "  if epoch%1 == 0:\n",
        "    print(f\"Epoch {epoch+1}: Weight(w) = {w:.3f}, Loss(MSE) = {l:.8f}\")\n",
        "\n",
        "print(f\"Prediction after training: f(7) = {forward(7):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIRxKpGKTq1T",
        "outputId": "d0b9291c-040b-4bc2-fa2b-e60cebe1698b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(7) = 0.0000\n",
            "Epoch 1: Weight(w) = 1.080, Loss(MSE) = 30.00000000\n",
            "Epoch 2: Weight(w) = 1.577, Loss(MSE) = 6.34799910\n",
            "Epoch 3: Weight(w) = 1.805, Loss(MSE) = 1.34323680\n",
            "Epoch 4: Weight(w) = 1.910, Loss(MSE) = 0.28422886\n",
            "Epoch 5: Weight(w) = 1.959, Loss(MSE) = 0.06014294\n",
            "Epoch 6: Weight(w) = 1.981, Loss(MSE) = 0.01272627\n",
            "Epoch 7: Weight(w) = 1.991, Loss(MSE) = 0.00269286\n",
            "Epoch 8: Weight(w) = 1.996, Loss(MSE) = 0.00056981\n",
            "Epoch 9: Weight(w) = 1.998, Loss(MSE) = 0.00012057\n",
            "Epoch 10: Weight(w) = 1.999, Loss(MSE) = 0.00002551\n",
            "Epoch 11: Weight(w) = 2.000, Loss(MSE) = 0.00000540\n",
            "Epoch 12: Weight(w) = 2.000, Loss(MSE) = 0.00000114\n",
            "Epoch 13: Weight(w) = 2.000, Loss(MSE) = 0.00000024\n",
            "Epoch 14: Weight(w) = 2.000, Loss(MSE) = 0.00000005\n",
            "Epoch 15: Weight(w) = 2.000, Loss(MSE) = 0.00000001\n",
            "Prediction after training: f(7) = 13.9999\n",
            "CPU times: user 6.47 ms, sys: 0 ns, total: 6.47 ms\n",
            "Wall time: 6.89 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second, we will do this by\n",
        "1. <B>Prediction:</B> Manually\n",
        "2. <B>Gradient Calculation:</B> Autograd\n",
        "3. <B>Loss Computation:</B> Manually\n",
        "4. <B>Parameters Update:</B> Manually"
      ],
      "metadata": {
        "id": "vNlmpOf6djoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import torch\n",
        "# Manually finding the f = w*x using Deep Learning\n",
        "\n",
        "# Here, f = 2*x  i.e. w = 2\n",
        "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)\n",
        "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True) # Initializing the value of w = 0.0\n",
        "\n",
        "# Model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "# Loss = MSE\n",
        "def loss(y, y_predicted): # Finds the loss value\n",
        "  return ((y_predicted - y)**2).mean() # Mean Squared Error\n",
        "\n",
        "# Gradient (not using NumPy array anymore i.e. no need to calculate the gradient)\n",
        "# MSE = ((w*x - y)**2)/N  i.e.  δϵ/δw = 2(w*x - y)x/N\n",
        "# def gradient(x, y, y_predicted): # Compute the gradient\n",
        "#   return np.dot(2*x, y_predicted - y).mean()\n",
        "\n",
        "print(f\"Prediction before training: f(7) = {forward(7):.4f}\")\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01 # Fixing the Learning Rate(η)\n",
        "n_iters = 25 # Number of iterations, change these 2 and check the outputs\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # Prediction = forward pass\n",
        "  y_predicted = forward(X)\n",
        "\n",
        "  # Loss\n",
        "  l = loss(Y, y_predicted)\n",
        "\n",
        "  # Gradients = backward pass\n",
        "  l.backward() # δϵ/δw\n",
        "\n",
        "  # Update Weights\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate*w.grad\n",
        "  w.grad.zero_() # Resets the gradient to zero, optimization step\n",
        "  if epoch%1 == 0:\n",
        "    print(f\"Epoch {epoch+1}: Weight(w) = {w:.3f}, Loss(MSE) = {l:.8f}\")\n",
        "\n",
        "print(f\"Prediction after training: f(7) = {forward(7):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCxW1VarYlnY",
        "outputId": "0e6728ce-3f65-4be0-cb24-1e8ce9a4893a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(7) = 0.0000\n",
            "Epoch 1: Weight(w) = 0.300, Loss(MSE) = 30.00000000\n",
            "Epoch 2: Weight(w) = 0.555, Loss(MSE) = 21.67499924\n",
            "Epoch 3: Weight(w) = 0.772, Loss(MSE) = 15.66018772\n",
            "Epoch 4: Weight(w) = 0.956, Loss(MSE) = 11.31448650\n",
            "Epoch 5: Weight(w) = 1.113, Loss(MSE) = 8.17471695\n",
            "Epoch 6: Weight(w) = 1.246, Loss(MSE) = 5.90623236\n",
            "Epoch 7: Weight(w) = 1.359, Loss(MSE) = 4.26725292\n",
            "Epoch 8: Weight(w) = 1.455, Loss(MSE) = 3.08308983\n",
            "Epoch 9: Weight(w) = 1.537, Loss(MSE) = 2.22753215\n",
            "Epoch 10: Weight(w) = 1.606, Loss(MSE) = 1.60939169\n",
            "Epoch 11: Weight(w) = 1.665, Loss(MSE) = 1.16278565\n",
            "Epoch 12: Weight(w) = 1.716, Loss(MSE) = 0.84011245\n",
            "Epoch 13: Weight(w) = 1.758, Loss(MSE) = 0.60698116\n",
            "Epoch 14: Weight(w) = 1.794, Loss(MSE) = 0.43854395\n",
            "Epoch 15: Weight(w) = 1.825, Loss(MSE) = 0.31684780\n",
            "Epoch 16: Weight(w) = 1.851, Loss(MSE) = 0.22892261\n",
            "Epoch 17: Weight(w) = 1.874, Loss(MSE) = 0.16539653\n",
            "Epoch 18: Weight(w) = 1.893, Loss(MSE) = 0.11949898\n",
            "Epoch 19: Weight(w) = 1.909, Loss(MSE) = 0.08633806\n",
            "Epoch 20: Weight(w) = 1.922, Loss(MSE) = 0.06237914\n",
            "Epoch 21: Weight(w) = 1.934, Loss(MSE) = 0.04506890\n",
            "Epoch 22: Weight(w) = 1.944, Loss(MSE) = 0.03256231\n",
            "Epoch 23: Weight(w) = 1.952, Loss(MSE) = 0.02352631\n",
            "Epoch 24: Weight(w) = 1.960, Loss(MSE) = 0.01699772\n",
            "Epoch 25: Weight(w) = 1.966, Loss(MSE) = 0.01228084\n",
            "Prediction after training: f(7) = 13.7592\n",
            "CPU times: user 23.4 ms, sys: 1 ms, total: 24.4 ms\n",
            "Wall time: 24.7 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Third, we will do this by\n",
        "1. <B>Prediction:</B> Manually\n",
        "2. <B>Gradient Calculation:</B> Autograd\n",
        "3. <B>Loss Computation:</B> PyTorch Loss\n",
        "4. <B>Parameters Update:</B> PyTorch Optimizer"
      ],
      "metadata": {
        "id": "Li5AkfHHdkib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Steps\n",
        "# 1) Design the model (input size, output size, forward pass)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#   - Forward pass: compute prediction\n",
        "#   - Backward pass: compute gradients\n",
        "#   - Update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# Manually finding the f = w*x using Deep Learning\n",
        "\n",
        "# Here, f = 2*x  i.e. w = 2\n",
        "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)\n",
        "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True) # Initializing the value of w = 0.0\n",
        "\n",
        "# Model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "# Loss = MSE (Since not manually doing)\n",
        "# def loss(y, y_predicted): # Finds the loss value\n",
        "#   return ((y_predicted - y)**2).mean() # Mean Squared Error\n",
        "\n",
        "# Gradient (not using NumPy array anymore i.e. no need to calculate the gradient)\n",
        "# MSE = ((w*x - y)**2)/N  i.e.  δϵ/δw = 2(w*x - y)x/N\n",
        "# def gradient(x, y, y_predicted): # Compute the gradient\n",
        "#   return np.dot(2*x, y_predicted - y).mean()\n",
        "\n",
        "print(f\"Prediction before training: f(7) = {forward(7):.4f}\")\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01 # Fixing the Learning Rate(η)\n",
        "n_iters = 25 # Number of iterations, change these 2 and check the outputs\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([w], lr = learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # Prediction = forward pass\n",
        "  y_predicted = forward(X)\n",
        "\n",
        "  # Loss\n",
        "  l = loss(Y, y_predicted)\n",
        "\n",
        "  # Gradients = backward pass\n",
        "  l.backward() # δϵ/δw\n",
        "\n",
        "  # Update Weights\n",
        "  # with torch.no_grad():\n",
        "    # w -= learning_rate*w.grad\n",
        "  optimizer.step()\n",
        "  # w.grad.zero_() # Resets the gradient to zero, optimization step\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%1 == 0:\n",
        "    print(f\"Epoch {epoch+1}: Weight(w) = {w:.3f}, Loss(MSE) = {l:.8f}\")\n",
        "\n",
        "print(f\"Prediction after training: f(7) = {forward(7):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqxgkTGddk4L",
        "outputId": "0228770e-9670-4178-d7f4-439b4209a4c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(7) = 0.0000\n",
            "Epoch 1: Weight(w) = 0.300, Loss(MSE) = 30.00000000\n",
            "Epoch 2: Weight(w) = 0.555, Loss(MSE) = 21.67499924\n",
            "Epoch 3: Weight(w) = 0.772, Loss(MSE) = 15.66018772\n",
            "Epoch 4: Weight(w) = 0.956, Loss(MSE) = 11.31448650\n",
            "Epoch 5: Weight(w) = 1.113, Loss(MSE) = 8.17471695\n",
            "Epoch 6: Weight(w) = 1.246, Loss(MSE) = 5.90623236\n",
            "Epoch 7: Weight(w) = 1.359, Loss(MSE) = 4.26725292\n",
            "Epoch 8: Weight(w) = 1.455, Loss(MSE) = 3.08308983\n",
            "Epoch 9: Weight(w) = 1.537, Loss(MSE) = 2.22753215\n",
            "Epoch 10: Weight(w) = 1.606, Loss(MSE) = 1.60939169\n",
            "Epoch 11: Weight(w) = 1.665, Loss(MSE) = 1.16278565\n",
            "Epoch 12: Weight(w) = 1.716, Loss(MSE) = 0.84011245\n",
            "Epoch 13: Weight(w) = 1.758, Loss(MSE) = 0.60698116\n",
            "Epoch 14: Weight(w) = 1.794, Loss(MSE) = 0.43854395\n",
            "Epoch 15: Weight(w) = 1.825, Loss(MSE) = 0.31684780\n",
            "Epoch 16: Weight(w) = 1.851, Loss(MSE) = 0.22892261\n",
            "Epoch 17: Weight(w) = 1.874, Loss(MSE) = 0.16539653\n",
            "Epoch 18: Weight(w) = 1.893, Loss(MSE) = 0.11949898\n",
            "Epoch 19: Weight(w) = 1.909, Loss(MSE) = 0.08633806\n",
            "Epoch 20: Weight(w) = 1.922, Loss(MSE) = 0.06237914\n",
            "Epoch 21: Weight(w) = 1.934, Loss(MSE) = 0.04506890\n",
            "Epoch 22: Weight(w) = 1.944, Loss(MSE) = 0.03256231\n",
            "Epoch 23: Weight(w) = 1.952, Loss(MSE) = 0.02352631\n",
            "Epoch 24: Weight(w) = 1.960, Loss(MSE) = 0.01699772\n",
            "Epoch 25: Weight(w) = 1.966, Loss(MSE) = 0.01228084\n",
            "Prediction after training: f(7) = 13.7592\n",
            "CPU times: user 2.85 s, sys: 778 ms, total: 3.63 s\n",
            "Wall time: 6.72 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forth, we will do this by\n",
        "1. <B>Prediction:</B> PyTorch Model\n",
        "2. <B>Gradient Calculation:</B> Autograd\n",
        "3. <B>Loss Computation:</B> PyTorch Loss\n",
        "4. <B>Parameters Update:</B> PyTorch Optimizer"
      ],
      "metadata": {
        "id": "-Qso9dmId-Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Steps\n",
        "# 1) Design the model (input size, output size, forward pass)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#   - Forward pass: compute prediction\n",
        "#   - Backward pass: compute gradients\n",
        "#   - Update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# Finding the f = w*x using Deep Learning\n",
        "\n",
        "# Here, f = 2*x  i.e. w = 2\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype = torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype = torch.float32)\n",
        "# w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True) # Initializing the value of w = 0.0\n",
        "X_test = torch.tensor([7], dtype = torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(\"No. of samples:\", n_samples, \"No. of features:\", n_features)\n",
        "\n",
        "input_size, output_size = n_features, n_features\n",
        "model = nn.Linear(input_size, output_size) # Linear regression model\n",
        "\n",
        "# Model prediction\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "\n",
        "# Loss = MSE (Since not manually doing)\n",
        "# def loss(y, y_predicted): # Finds the loss value\n",
        "#   return ((y_predicted - y)**2).mean() # Mean Squared Error\n",
        "\n",
        "# Gradient (not using NumPy array anymore i.e. no need to calculate the gradient)\n",
        "# MSE = ((w*x - y)**2)/N  i.e.  δϵ/δw = 2(w*x - y)x/N\n",
        "# def gradient(x, y, y_predicted): # Compute the gradient\n",
        "#   return np.dot(2*x, y_predicted - y).mean()\n",
        "\n",
        "print(f\"Prediction before training: f(7) = {model(X_test).item():.4f}\")\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01 # Fixing the Learning Rate(η)\n",
        "n_iters = 25 # Number of iterations, change these 2 and check the outputs\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "#  Prediction = forward pass\n",
        "  y_predicted = model(X)\n",
        "\n",
        "  # Loss\n",
        "  l = loss(Y, y_predicted)\n",
        "\n",
        "  # Gradients = backward pass\n",
        "  l.backward() # δϵ/δw\n",
        "\n",
        "  # Update Weights\n",
        "#   with torch.no_grad():\n",
        "#     w -= learning_rate*w.grad\n",
        "  optimizer.step()\n",
        "#   w.grad.zero_() # Resets the gradient to zero, optimization step\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%1 == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f\"Epoch {epoch+1}: Weight(w) = {w[0][0].item():.3f}, Loss(MSE) = {l:.8f}\")\n",
        "\n",
        "print(f\"Prediction after training: f(7) = {model(X_test).item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIBjcQehd-uQ",
        "outputId": "14347250-37b8-4693-bee5-144ff87f7d7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of samples: 4 No. of features: 1\n",
            "Prediction before training: f(7) = 3.0258\n",
            "Epoch 1: Weight(w) = 0.765, Loss(MSE) = 21.13142776\n",
            "Epoch 2: Weight(w) = 0.975, Loss(MSE) = 14.66282082\n",
            "Epoch 3: Weight(w) = 1.149, Loss(MSE) = 10.17439079\n",
            "Epoch 4: Weight(w) = 1.294, Loss(MSE) = 7.05996275\n",
            "Epoch 5: Weight(w) = 1.415, Loss(MSE) = 4.89892483\n",
            "Epoch 6: Weight(w) = 1.516, Loss(MSE) = 3.39942646\n",
            "Epoch 7: Weight(w) = 1.600, Loss(MSE) = 2.35895443\n",
            "Epoch 8: Weight(w) = 1.670, Loss(MSE) = 1.63699222\n",
            "Epoch 9: Weight(w) = 1.728, Loss(MSE) = 1.13603699\n",
            "Epoch 10: Weight(w) = 1.777, Loss(MSE) = 0.78843331\n",
            "Epoch 11: Weight(w) = 1.817, Loss(MSE) = 0.54723787\n",
            "Epoch 12: Weight(w) = 1.851, Loss(MSE) = 0.37987661\n",
            "Epoch 13: Weight(w) = 1.879, Loss(MSE) = 0.26374704\n",
            "Epoch 14: Weight(w) = 1.902, Loss(MSE) = 0.18316615\n",
            "Epoch 15: Weight(w) = 1.922, Loss(MSE) = 0.12725203\n",
            "Epoch 16: Weight(w) = 1.938, Loss(MSE) = 0.08845331\n",
            "Epoch 17: Weight(w) = 1.951, Loss(MSE) = 0.06153070\n",
            "Epoch 18: Weight(w) = 1.963, Loss(MSE) = 0.04284897\n",
            "Epoch 19: Weight(w) = 1.972, Loss(MSE) = 0.02988505\n",
            "Epoch 20: Weight(w) = 1.980, Loss(MSE) = 0.02088877\n",
            "Epoch 21: Weight(w) = 1.986, Loss(MSE) = 0.01464554\n",
            "Epoch 22: Weight(w) = 1.991, Loss(MSE) = 0.01031257\n",
            "Epoch 23: Weight(w) = 1.996, Loss(MSE) = 0.00730510\n",
            "Epoch 24: Weight(w) = 2.000, Loss(MSE) = 0.00521743\n",
            "Epoch 25: Weight(w) = 2.003, Loss(MSE) = 0.00376792\n",
            "Prediction after training: f(7) = 13.9598\n",
            "CPU times: user 30.3 ms, sys: 7.55 ms, total: 37.8 ms\n",
            "Wall time: 35.9 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Last, we want a custom model with PyTorch with the followings\n",
        "1. <B>Prediction:</B> PyTorch Model\n",
        "2. <B>Gradient Calculation:</B> Autograd\n",
        "3. <B>Loss Computation:</B> PyTorch Loss\n",
        "4. <B>Parameters Update:</B> PyTorch Optimizer"
      ],
      "metadata": {
        "id": "hX5mpRLMAdFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Steps\n",
        "# 1) Design the model (input size, output size, forward pass)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#   - Forward pass: compute prediction\n",
        "#   - Backward pass: compute gradients\n",
        "#   - Update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype = torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype = torch.float32)\n",
        "X_test = torch.tensor([7], dtype = torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(\"No. of samples:\", n_samples, \"No. of features:\", n_features)\n",
        "\n",
        "input_size, output_size = n_features, n_features\n",
        "# model = nn.Linear(input_size, output_size) # Linear regression model\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    # Define layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size) # Custom Linear Regression Model\n",
        "\n",
        "print(f\"Prediction before training: f(7) = {model(X_test).item():.4f}\")\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01 # Fixing the Learning Rate(η)\n",
        "n_iters = 25 # Number of iterations, change these 2 and check the outputs\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "#  Prediction = forward pass\n",
        "  y_predicted = model(X)\n",
        "\n",
        "  # Loss\n",
        "  l = loss(Y, y_predicted)\n",
        "\n",
        "  # Gradients = backward pass\n",
        "  l.backward() # δϵ/δw\n",
        "\n",
        "  # Update Weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad() # Resets the gradient to zero, optimization step\n",
        "\n",
        "  if epoch%1 == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f\"Epoch {epoch+1}: Weight(w) = {w[0][0].item():.3f}, Loss(MSE) = {l:.8f}\")\n",
        "\n",
        "print(f\"Prediction after training: f(7) = {model(X_test).item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDHvaQO5AJ2g",
        "outputId": "f52e00b5-b20f-4fc1-beb9-cc88050a3d48"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of samples: 4 No. of features: 1\n",
            "Prediction before training: f(7) = -0.6305\n",
            "Epoch 1: Weight(w) = 0.378, Loss(MSE) = 38.50626755\n",
            "Epoch 2: Weight(w) = 0.661, Loss(MSE) = 26.72090912\n",
            "Epoch 3: Weight(w) = 0.896, Loss(MSE) = 18.54328156\n",
            "Epoch 4: Weight(w) = 1.092, Loss(MSE) = 12.86898804\n",
            "Epoch 5: Weight(w) = 1.255, Loss(MSE) = 8.93169975\n",
            "Epoch 6: Weight(w) = 1.391, Loss(MSE) = 6.19968796\n",
            "Epoch 7: Weight(w) = 1.504, Loss(MSE) = 4.30398846\n",
            "Epoch 8: Weight(w) = 1.599, Loss(MSE) = 2.98859024\n",
            "Epoch 9: Weight(w) = 1.677, Loss(MSE) = 2.07585001\n",
            "Epoch 10: Weight(w) = 1.743, Loss(MSE) = 1.44250655\n",
            "Epoch 11: Weight(w) = 1.797, Loss(MSE) = 1.00303042\n",
            "Epoch 12: Weight(w) = 1.842, Loss(MSE) = 0.69807494\n",
            "Epoch 13: Weight(w) = 1.880, Loss(MSE) = 0.48645988\n",
            "Epoch 14: Weight(w) = 1.911, Loss(MSE) = 0.33961198\n",
            "Epoch 15: Weight(w) = 1.937, Loss(MSE) = 0.23770514\n",
            "Epoch 16: Weight(w) = 1.959, Loss(MSE) = 0.16698191\n",
            "Epoch 17: Weight(w) = 1.977, Loss(MSE) = 0.11789630\n",
            "Epoch 18: Weight(w) = 1.992, Loss(MSE) = 0.08382455\n",
            "Epoch 19: Weight(w) = 2.005, Loss(MSE) = 0.06017089\n",
            "Epoch 20: Weight(w) = 2.015, Loss(MSE) = 0.04374621\n",
            "Epoch 21: Weight(w) = 2.023, Loss(MSE) = 0.03233738\n",
            "Epoch 22: Weight(w) = 2.031, Loss(MSE) = 0.02440933\n",
            "Epoch 23: Weight(w) = 2.036, Loss(MSE) = 0.01889637\n",
            "Epoch 24: Weight(w) = 2.041, Loss(MSE) = 0.01505937\n",
            "Epoch 25: Weight(w) = 2.045, Loss(MSE) = 0.01238525\n",
            "Prediction after training: f(7) = 14.1149\n",
            "CPU times: user 41.8 ms, sys: 4.67 ms, total: 46.5 ms\n",
            "Wall time: 44.1 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression using PyTorch"
      ],
      "metadata": {
        "id": "S-L8ABt9B_w4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kYuINHHtCAEq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}