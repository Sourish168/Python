{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJUJqzVfJFp3vpJfzPEmnl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sourish168/Python/blob/main/PyTorch/PyTorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction and Installation\n",
        "- From https://pytorch.org/ we can download the required package of PyTorch in our machine(Linux/Mac/Windows).\n",
        "- If gpu is available then the cuda version is preferable for NVIDIA GPUs only.\n",
        "- In local mechine we have to create a virtual environment and install the appropiate version of python.\n",
        "- In Google Colab we have to install PyTorch by \"!pip install torch\" command.\n",
        "- By \"torch.cuda.is_available()\" we can check if the cuda is there or not."
      ],
      "metadata": {
        "id": "ugEeAVTRoSyj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5AKWDZRYma0V",
        "outputId": "96b7fa88-eb57-45b0-a284-588057fe61ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available() # False means there is no cuda in the machine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_9FDd0q7yip",
        "outputId": "f43772ee-b4a5-4405-83cf-7232bd313c42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Basics\n",
        "- In NumPy we have used vectors, matrices, tensors. In PyTorch everything starts with tensors i.e. 1D, 2D, nD arrays."
      ],
      "metadata": {
        "id": "p0bRM3vE8Nek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.empty(1) # Scalar\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qKcD9KK8Nyq",
        "outputId": "d6da6b15-f463-4f84-86b2-b7107de8efc2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.8665e+32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2, 3, 4) # 3D array\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD1jYWu989KS",
        "outputId": "5a3316f5-39c4-4e06-9a5a-d5f64f2b0004"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 5.7344e-30,  4.4355e-41,  5.7344e-30,  4.4355e-41],\n",
            "         [        nan,  0.0000e+00,  1.8728e+31,  1.4153e-43],\n",
            "         [ 3.2892e+14,  4.4354e-41,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "        [[ 8.9683e-44,  0.0000e+00,  2.6905e-43,  0.0000e+00],\n",
            "         [-6.3723e+09,  4.4354e-41,  0.0000e+00,  1.4013e-45],\n",
            "         [ 9.2327e-26,  3.2695e-41,  0.0000e+00,  0.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 2, 3) # 3D array of zeros\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjUbfKlg9Owk",
        "outputId": "9661b74f-b804-4bb3-feba-e7a2b80835c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2, 3, dtype = torch.float16) # 2D array of ones\n",
        "print(x)\n",
        "print(\"\\n\", x.dtype) # Prints the datatype of x\n",
        "print(\"\\n\", x.size()) # Prints the size of x\n",
        "print(\"\\n\", x.shape) # Prints the shape of x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmXwva4a9bEe",
        "outputId": "72b7ea68-5868-4a07-8f14-7ff8522f2fd9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float16)\n",
            "\n",
            " torch.float16\n",
            "\n",
            " torch.Size([2, 3])\n",
            "\n",
            " torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.5, 0.1, 3.6]) # Creates a tensor from a list\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBavwzZN-NoM",
        "outputId": "d19fb6e7-a41b-4320-dc23-25cbad068dc9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.5000, 0.1000, 3.6000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 2) # 2D array of random values\n",
        "y = torch.rand(2, 2)\n",
        "print(\"x =\\n\", x)\n",
        "print(\"\\ny =\\n\", y)\n",
        "print(\"\\nx+y =\\n\", x+y) # Addition\n",
        "print(\"\\ntorch.add(x, y) =\\n\", torch.add(x, y)) # Addition\n",
        "print(\"\\nx-y =\\n\", x-y) # Subtraction\n",
        "print(\"\\ntorch.sub(x, y) =\\n\", torch.sub(x, y)) # Subtraction\n",
        "print(\"\\nx*y =\\n\", x*y) # Multiplication\n",
        "print(\"\\ntorch.mul(x, y) =\\n\", torch.mul(x, y)) # Multiplication\n",
        "print(\"\\nx/y =\\n\", x/y) # Division\n",
        "print(\"\\ntorch.div(x, y) =\\n\", torch.div(x, y)) # Division"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rmI5Npm-xzy",
        "outputId": "8f49f8ef-d1e5-49c1-c006-8cb3b1dbb056"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =\n",
            " tensor([[0.7870, 0.4952],\n",
            "        [0.1715, 0.4954]])\n",
            "\n",
            "y =\n",
            " tensor([[0.5973, 0.2423],\n",
            "        [0.5274, 0.0733]])\n",
            "\n",
            "x+y =\n",
            " tensor([[1.3843, 0.7376],\n",
            "        [0.6989, 0.5687]])\n",
            "\n",
            "torch.add(x, y) =\n",
            " tensor([[1.3843, 0.7376],\n",
            "        [0.6989, 0.5687]])\n",
            "\n",
            "x-y =\n",
            " tensor([[ 0.1896,  0.2529],\n",
            "        [-0.3559,  0.4221]])\n",
            "\n",
            "torch.sub(x, y) =\n",
            " tensor([[ 0.1896,  0.2529],\n",
            "        [-0.3559,  0.4221]])\n",
            "\n",
            "x*y =\n",
            " tensor([[0.4701, 0.1200],\n",
            "        [0.0904, 0.0363]])\n",
            "\n",
            "torch.mul(x, y) =\n",
            " tensor([[0.4701, 0.1200],\n",
            "        [0.0904, 0.0363]])\n",
            "\n",
            "x/y =\n",
            " tensor([[1.3175, 2.0436],\n",
            "        [0.3251, 6.7598]])\n",
            "\n",
            "torch.div(x, y) =\n",
            " tensor([[1.3175, 2.0436],\n",
            "        [0.3251, 6.7598]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 2)\n",
        "y = torch.rand(2, 2)\n",
        "print(\"x =\\n\", x)\n",
        "print(\"\\ny =\\n\", y)\n",
        "print(\"\\nx+y =\\n\", x+y) # Addition\n",
        "y.add_(x) # Inplace addition\n",
        "print(\"\\nNow, y =\\n\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuDBvpal_Ji4",
        "outputId": "5e6c71dd-97fb-4d20-b0e9-9ce027e29e07"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =\n",
            " tensor([[0.6547, 0.3169],\n",
            "        [0.1159, 0.8991]])\n",
            "\n",
            "y =\n",
            " tensor([[0.6328, 0.8502],\n",
            "        [0.6011, 0.8069]])\n",
            "\n",
            "x+y =\n",
            " tensor([[1.2875, 1.1671],\n",
            "        [0.7170, 1.7060]])\n",
            "\n",
            "Now, y =\n",
            " tensor([[1.2875, 1.1671],\n",
            "        [0.7170, 1.7060]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing of a tensor in PyTorch\n",
        "x = torch.rand(5, 4)\n",
        "print(x)\n",
        "print(\"\\n\", x[:, 0]) # Prints the first column\n",
        "print(\"\\n\", x[1, :]) # Prints the second row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zml4ct74BSTi",
        "outputId": "874da762-ebe1-4740-ef9f-48dd6bca1fca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2758, 0.0263, 0.4842, 0.3037],\n",
            "        [0.9383, 0.4854, 0.5855, 0.4944],\n",
            "        [0.5045, 0.8050, 0.6152, 0.1146],\n",
            "        [0.6972, 0.2365, 0.1701, 0.5679],\n",
            "        [0.1362, 0.5831, 0.3701, 0.5951]])\n",
            "\n",
            " tensor([0.2758, 0.9383, 0.5045, 0.6972, 0.1362])\n",
            "\n",
            " tensor([0.9383, 0.4854, 0.5855, 0.4944])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping of a tensor in PyTorch\n",
        "x = torch.rand(4, 4)\n",
        "print(\"x =\", x)\n",
        "y = x.view(2, 8) # Reshapes the tensor to 2D of shape (2, 8)\n",
        "print(\"\\ny =\", y)\n",
        "z = x.view(16) # Reshapes the tensor to 1D of shape (16)\n",
        "print(\"\\nz =\", z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcKp7sX0B3Hh",
        "outputId": "8edd6946-3fb5-49dc-9c5c-b99e9d430379"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([[0.9847, 0.5975, 0.7559, 0.1402],\n",
            "        [0.5898, 0.6594, 0.3962, 0.7136],\n",
            "        [0.9404, 0.0475, 0.6655, 0.4802],\n",
            "        [0.1402, 0.3459, 0.9550, 0.7598]])\n",
            "\n",
            "y = tensor([[0.9847, 0.5975, 0.7559, 0.1402, 0.5898, 0.6594, 0.3962, 0.7136],\n",
            "        [0.9404, 0.0475, 0.6655, 0.4802, 0.1402, 0.3459, 0.9550, 0.7598]])\n",
            "\n",
            "z = tensor([0.9847, 0.5975, 0.7559, 0.1402, 0.5898, 0.6594, 0.3962, 0.7136, 0.9404,\n",
            "        0.0475, 0.6655, 0.4802, 0.1402, 0.3459, 0.9550, 0.7598])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4, 4)\n",
        "print(\"x =\", x)\n",
        "y = x.view(-1, 8) # Reshapes the tensor to 2D of shape (2, 8), Negative value by default choose the proper dimension\n",
        "print(\"\\ny =\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEamdPLhCNH_",
        "outputId": "913f3073-29f3-452c-f065-fc7112e62736"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([[0.0124, 0.9629, 0.6070, 0.7891],\n",
            "        [0.5116, 0.8248, 0.1646, 0.9194],\n",
            "        [0.5410, 0.4994, 0.0865, 0.5310],\n",
            "        [0.9660, 0.4909, 0.0985, 0.1097]])\n",
            "\n",
            "y = tensor([[0.0124, 0.9629, 0.6070, 0.7891, 0.5116, 0.8248, 0.1646, 0.9194],\n",
            "        [0.5410, 0.4994, 0.0865, 0.5310, 0.9660, 0.4909, 0.0985, 0.1097]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If there is no GPU memory then PyTorch and NumPy shares the same memory location thus the output changes\n",
        "import numpy as np\n",
        "a = torch.ones(5)\n",
        "print(\"a =\", a)\n",
        "b = a.numpy() # Creates a numpy array from a tensor\n",
        "print(\"\\nb =\", b)\n",
        "print(\"\\nType of a =\", type(a))\n",
        "print(\"\\nType of b =\", type(b))\n",
        "a.add_(1)\n",
        "print(\"\\nNow, a =\", a)\n",
        "print(\"\\nNow, b =\", b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gffkflHDDffz",
        "outputId": "ac6533c6-a794-45a0-daa0-3754bc4e7179"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a = tensor([1., 1., 1., 1., 1.])\n",
            "\n",
            "b = [1. 1. 1. 1. 1.]\n",
            "\n",
            "Type of a = <class 'torch.Tensor'>\n",
            "\n",
            "Type of b = <class 'numpy.ndarray'>\n",
            "\n",
            "Now, a = tensor([2., 2., 2., 2., 2.])\n",
            "\n",
            "Now, b = [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "print(\"a =\", a)\n",
        "b = torch.from_numpy(a) # Creates a tensor from a numpy array\n",
        "print(\"\\nb =\", b)\n",
        "print(\"\\nType of a =\", type(a))\n",
        "print(\"\\nType of b =\", type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2yMaMkrECWk",
        "outputId": "429b3e81-f0a3-4727-b4fe-79b35f971afa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a = [1. 1. 1. 1. 1.]\n",
            "\n",
            "b = tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "\n",
            "Type of a = <class 'numpy.ndarray'>\n",
            "\n",
            "Type of b = <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since in this case, torch.cuda.is_available() = False\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\") # Creates a device object\n",
        "  print(device)\n",
        "  x = torch.ones(5, device = device) # Creates a tensor on the GPU\n",
        "  y = torch.ones(5)\n",
        "  y = y.to(device) # Moves the tensor to the GPU\n",
        "  z = x + y\n",
        "  print(z)\n",
        "  z = z.to(\"cpu\") # Moves the tensor to the CPU\n",
        "  print(z)\n",
        "else:\n",
        "  print(\"No GPU available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvjH0MZdFHq9",
        "outputId": "9083337c-5773-403e-8d05-2fee31b490cd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(x) # Later for optimization steps the tensor needs to calculate the gradient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbolIfuXFnya",
        "outputId": "722b1802-f802-4958-a6ae-4d70df2857b2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Calculation with Autograd in PyTorch\n",
        "- In Deep Learning, gradient calculation is a very crutial step for optimization."
      ],
      "metadata": {
        "id": "9uY4IGU6GaOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.randn(3, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(\"x =\", x)\n",
        "y = x + 2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\ny =\", y)\n",
        "z = y*y*2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\nz =\", z)\n",
        "p = z.mean() # Creates a tensor with requires_grad = False\n",
        "print(\"\\np =\", p)\n",
        "p.backward() # Calculates the gradient of p with respect to x i.e. dp/dx\n",
        "print(\"\\nx.grad =\", x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsDXjwJzGFFG",
        "outputId": "cd836947-7965-48a7-af4a-ffebf7522a19"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([0.5580, 0.4624, 0.7128], requires_grad=True)\n",
            "\n",
            "y = tensor([2.5580, 2.4624, 2.7128], grad_fn=<AddBackward0>)\n",
            "\n",
            "z = tensor([13.0869, 12.1266, 14.7182], grad_fn=<MulBackward0>)\n",
            "\n",
            "p = tensor(13.3106, grad_fn=<MeanBackward0>)\n",
            "\n",
            "x.grad = tensor([3.4107, 3.2832, 3.6170])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad = False) # Creates a tensor with requires_grad = True\n",
        "print(\"x =\", x)\n",
        "y = x + 2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\ny =\", y)\n",
        "z = y*y*2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\nz =\", z)\n",
        "p = z.mean() # Creates a tensor with requires_grad = False\n",
        "print(\"\\np =\", p)\n",
        "p.backward() # Calculates the gradient of p with respect to x i.e. dp/dx\n",
        "print(\"\\nx.grad =\", x.grad) # Since requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "wREQhwl0ICWU",
        "outputId": "4233acd3-bba1-4f9f-c1e8-fba35a23b672"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([-1.5262,  0.2790,  1.0887])\n",
            "\n",
            "y = tensor([0.4738, 2.2790, 3.0887])\n",
            "\n",
            "z = tensor([ 0.4490, 10.3881, 19.0807])\n",
            "\n",
            "p = tensor(9.9726)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-ff0155360e09>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Creates a tensor with requires_grad = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\np =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculates the gradient of p with respect to x i.e. dp/dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nx.grad =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Since requires_grad = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(\"x =\", x)\n",
        "y = x + 2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\ny =\", y)\n",
        "z = y*y*2 # Creates a tensor with requires_grad = False\n",
        "print(\"\\nz =\", z)\n",
        "v = torch.tensor([0.1, 10.0, 0.001], dtype = torch.float32)\n",
        "z.backward(v) # Calculates the gradient of p with respect to x i.e. dp/dx\n",
        "print(\"\\nx.grad =\", x.grad) # Vector Jacobian Product in the background"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5tsCCNuJBaH",
        "outputId": "e0c68661-553e-4def-fbd9-c69aaaea0b32"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([-0.0687, -0.8293, -0.0447], requires_grad=True)\n",
            "\n",
            "y = tensor([1.9313, 1.1707, 1.9553], grad_fn=<AddBackward0>)\n",
            "\n",
            "z = tensor([7.4598, 2.7409, 7.6466], grad_fn=<MulBackward0>)\n",
            "\n",
            "x.grad = tensor([7.7252e-01, 4.6826e+01, 7.8213e-03])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preventing gradient history\n",
        "x = torch.randn(3, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(\"x =\", x)\n",
        "x.requires_grad_(False) # Prevents gradient history\n",
        "print(\"\\nx =\", x)\n",
        "print(\"\\n\", 50*\"-\")\n",
        "x = torch.randn(3, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(\"\\nx =\", x)\n",
        "y = x.detach() # Detaches the gradient history\n",
        "print(\"\\ny =\", y)\n",
        "print(\"\\n\", 50*\"-\")\n",
        "x = torch.randn(3, requires_grad = True) # Creates a tensor with requires_grad = True\n",
        "print(\"\\nx =\", x)\n",
        "with torch.no_grad(): # Prevents gradient history\n",
        "  y = x + 2\n",
        "  print(\"\\ny =\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_GgOULiKfs-",
        "outputId": "dd16a121-5935-49fa-e6a2-58badd48f764"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([ 0.1956, -0.0141, -0.1218], requires_grad=True)\n",
            "\n",
            "x = tensor([ 0.1956, -0.0141, -0.1218])\n",
            "\n",
            " --------------------------------------------------\n",
            "\n",
            "x = tensor([0.6713, 0.0724, 0.5710], requires_grad=True)\n",
            "\n",
            "y = tensor([0.6713, 0.0724, 0.5710])\n",
            "\n",
            " --------------------------------------------------\n",
            "\n",
            "x = tensor([ 0.7072, -0.6595, -0.1999], requires_grad=True)\n",
            "\n",
            "y = tensor([2.7072, 1.3405, 1.8001])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy Trainning Example\n",
        "weight = torch.ones(4, requires_grad = True)\n",
        "print(\"x =\", weight, \"\\n\")\n",
        "for epoch in range(3):\n",
        "  model_output = (weight*3).sum() # Dummy model output\n",
        "  print(model_output)\n",
        "  model_output.backward()\n",
        "  print(weight.grad)\n",
        "  weight.grad.zero_() # Resets the gradient to zero, optimization step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8PbZL25Mx98",
        "outputId": "8d84185d-5fd7-4bfa-c118-126e572ddffb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([1., 1., 1., 1.], requires_grad=True) \n",
            "\n",
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization Steps\n",
        "weight = torch.ones(4, requires_grad=True)\n",
        "print(\"x =\", weight)\n",
        "optimizer = torch.optim.SGD([weight], lr=0.01)  # Pass [weight] as a single-element list, Stochastic Gradient Descent\n",
        "optimizer.step()  # Optimization step\n",
        "optimizer.zero_grad()  # Resets the gradient to zero, optimization step\n",
        "print(\"\\nOptimizer =\", optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tikk5tjzNUF3",
        "outputId": "53e8f618-692e-4469-af2b-063060a1a8b5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "\n",
            "Optimizer = SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation in PyTorch\n",
        "-"
      ],
      "metadata": {
        "id": "fibbBN5yPrBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n"
      ],
      "metadata": {
        "id": "oqWFFvfoOnDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}